{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b024889c-4c4b-4d9b-a780-0c03c4afbb0b",
   "metadata": {},
   "source": [
    "### Automated anomaly detection using PyOD and Auto-Sklearn\n",
    "Hyberband search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b9869dd-9366-43d1-989e-573b7dd7e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from autosklearn.metrics import roc_auc, average_precision\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, PredefinedSplit\n",
    "import autosklearn.classification\n",
    "import os, sys\n",
    "p = os.path.abspath('..')\n",
    "sys.path.insert(1, p)\n",
    "from utils import import_dataset, add_pyod_models_to_pipeline, balanced_split, get_metric_result\n",
    "# Add models to Auto-Sklearn\n",
    "add_pyod_models_to_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34e36a22-9046-429d-8058-385d68879a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bosh_object_callback(budget_type):\n",
    "    def get_smac_object(\n",
    "        scenario_dict,\n",
    "        seed,\n",
    "        ta,\n",
    "        ta_kwargs,\n",
    "        metalearning_configurations,\n",
    "        n_jobs,\n",
    "        dask_client,\n",
    "    ):\n",
    "        from smac.facade.smac_ac_facade import SMAC4AC\n",
    "        from smac.intensification.successive_halving import SuccessiveHalving\n",
    "        from smac.runhistory.runhistory2epm import RunHistory2EPM4LogCost\n",
    "        from smac.scenario.scenario import Scenario\n",
    "\n",
    "        if n_jobs > 1 or (dask_client and len(dask_client.nthreads()) > 1):\n",
    "            raise ValueError(\"Please make sure to guard the code invoking Auto-sklearn by \"\n",
    "                             \"`if __name__ == '__main__'` and remove this exception.\")\n",
    "\n",
    "        scenario = Scenario(scenario_dict)\n",
    "        if len(metalearning_configurations) > 0:\n",
    "            default_config = scenario.cs.get_default_configuration()\n",
    "            initial_configurations = [default_config] + metalearning_configurations\n",
    "        else:\n",
    "            initial_configurations = None\n",
    "        rh2EPM = RunHistory2EPM4LogCost\n",
    "\n",
    "        ta_kwargs['budget_type'] = budget_type\n",
    "\n",
    "        return SMAC4AC(\n",
    "            scenario=scenario,\n",
    "            rng=seed,\n",
    "            runhistory2epm=rh2EPM,\n",
    "            tae_runner=ta,\n",
    "            tae_runner_kwargs=ta_kwargs,\n",
    "            initial_configurations=initial_configurations,\n",
    "            run_id=seed,\n",
    "            intensifier=SuccessiveHalving,\n",
    "            intensifier_kwargs={\n",
    "                'initial_budget': 10.0,\n",
    "                'max_budget': 100,\n",
    "                'eta': 2,\n",
    "                'min_chall': 1\n",
    "            },\n",
    "            n_jobs=n_jobs,\n",
    "            dask_client=dask_client,\n",
    "        )\n",
    "    return get_smac_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcee3353-9a1e-495c-9887-1b76b11f54cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bohb_object_callback(budget_type):\n",
    "    def get_smac_object(\n",
    "        scenario_dict,\n",
    "        seed,\n",
    "        ta,\n",
    "        ta_kwargs,\n",
    "        metalearning_configurations,\n",
    "        n_jobs,\n",
    "        dask_client,\n",
    "    ):\n",
    "        from smac.facade.smac_ac_facade import SMAC4AC\n",
    "        from smac.intensification.hyperband import Hyperband\n",
    "        from smac.runhistory.runhistory2epm import RunHistory2EPM4LogCost\n",
    "        from smac.scenario.scenario import Scenario\n",
    "\n",
    "        if n_jobs > 1 or (dask_client and len(dask_client.nthreads()) > 1):\n",
    "            raise ValueError(\"Please make sure to guard the code invoking Auto-sklearn by \"\n",
    "                             \"`if __name__ == '__main__'` and remove this exception.\")\n",
    "\n",
    "        scenario = Scenario(scenario_dict)\n",
    "        if len(metalearning_configurations) > 0:\n",
    "            default_config = scenario.cs.get_default_configuration()\n",
    "            initial_configurations = [default_config] + metalearning_configurations\n",
    "        else:\n",
    "            initial_configurations = None\n",
    "        rh2EPM = RunHistory2EPM4LogCost\n",
    "\n",
    "        ta_kwargs['budget_type'] = budget_type\n",
    "\n",
    "        return SMAC4AC(\n",
    "            scenario=scenario,\n",
    "            rng=seed,\n",
    "            runhistory2epm=rh2EPM,\n",
    "            tae_runner=ta,\n",
    "            tae_runner_kwargs=ta_kwargs,\n",
    "            initial_configurations=initial_configurations,\n",
    "            run_id=seed,\n",
    "            intensifier=Hyperband,\n",
    "            intensifier_kwargs={\n",
    "                'initial_budget': 10.0,\n",
    "                'max_budget': 100,\n",
    "                'eta': 2,\n",
    "                'min_chall': 1\n",
    "            },\n",
    "            n_jobs=n_jobs,\n",
    "            dask_client=dask_client,\n",
    "        )\n",
    "    return get_smac_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc9dffe0-55f9-44d2-bb11-c725f4c711e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers to be included\n",
    "classifiers = [\n",
    "    'CBLOFClassifier',\n",
    "    'COPODClassifier',\n",
    "    'IForestClassifier',\n",
    "    'KNNClassifier',\n",
    "    'LOFClassifier',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63388c8e-e09b-4318-b3e0-3f6580ea5d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DataFrame\n",
    "df = import_dataset('../../data/Cardiotocography_withoutdupl_norm_05_v10.arff')\n",
    "# Subsample\n",
    "N = 5000\n",
    "if(len(df) > N):\n",
    "    df = df.sample(n=N)\n",
    "# Extract X, y\n",
    "X  = df.iloc[:, :-1]\n",
    "y = df['outlier']\n",
    "# Split to train, test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe4c554e-4a96-4f29-a871-b22bc389b5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johneegr/anaconda3/envs/env_thesis/lib/python3.8/site-packages/smac/intensification/parallel_scheduling.py:153: UserWarning: SuccessiveHalving is executed with 1 workers only. Consider to use pynisher to use all available workers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2022-03-25 13:36:56,643:Client-autosklearn.automl_common.common.utils.backend] Directory /tmp/auto-sklearn_tmp_9d93f1a8-ac2f-11ec-8241-69270db3aa3f/.auto-sklearn/ensembles does not exist\n",
      "auto-sklearn results:\n",
      "  Dataset name: cardiotocography\n",
      "  Metric: roc_auc\n",
      "  Best validation score: 0.701235\n",
      "  Number of target algorithm runs: 63\n",
      "  Number of successful target algorithm runs: 55\n",
      "  Number of crashed target algorithm runs: 7\n",
      "  Number of target algorithms that exceeded the time limit: 1\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resampling strategy\n",
    "#resampling_strategy = StratifiedShuffleSplit(n_splits=5, test_size=0.3)\n",
    "selected_indices = balanced_split(y_train)\n",
    "resampling_strategy = PredefinedSplit(test_fold=selected_indices)\n",
    "#\n",
    "automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=120,\n",
    "    per_run_time_limit=20,\n",
    "    metric=roc_auc,\n",
    "    scoring_functions = [roc_auc, average_precision],\n",
    "    initial_configurations_via_metalearning = 0,\n",
    "    ensemble_size = 0,\n",
    "    resampling_strategy=resampling_strategy,\n",
    "    include={\n",
    "        'classifier': ['extra_trees', 'gradient_boosting', 'random_forest'],\n",
    "        #'classifier': classifiers,\n",
    "        'feature_preprocessor': ['no_preprocessing']\n",
    "    },\n",
    "    get_smac_object_callback=get_bosh_object_callback('iterations'),\n",
    "    delete_tmp_folder_after_terminate=False\n",
    ")\n",
    "automl.fit(X_train, y_train, X_test, y_test, dataset_name='cardiotocography')\n",
    "\n",
    "# Print stats\n",
    "print(automl.sprint_statistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844ed971-6a55-440c-a029-84f11f065a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
