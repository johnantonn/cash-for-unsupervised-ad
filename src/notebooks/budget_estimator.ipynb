{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ee10de-2194-4cc6-beba-1e82972e3fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from autosklearn.classification import AutoSklearnClassifier\n",
    "p = os.path.abspath('..')\n",
    "sys.path.insert(1, p)\n",
    "from utils import add_to_autosklearn_pipeline\n",
    "from notebook_utils import get_search_space_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c198379-d0dd-4d31-8344-2a887c281bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "dataset = 'Cardiotocography'\n",
    "data_iter = 1 # dataset iteration\n",
    "# Import X_train, y_train, X_test, y_test\n",
    "dataset_dir = '../data/processed/'+dataset+'/iter'+str(data_iter)+'/'\n",
    "X_train = pd.read_csv(dataset_dir + 'X_train.csv')\n",
    "y_train = pd.read_csv(dataset_dir + 'y_train.csv')\n",
    "X_test = pd.read_csv(dataset_dir + 'X_test.csv')\n",
    "y_test = pd.read_csv(dataset_dir + 'y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37227461-73e4-48bb-a7eb-9466b967ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyOD classifiers\n",
    "search_space = 'sp1'\n",
    "classifiers = [\n",
    "    'CBLOFClassifier',\n",
    "    'COPODClassifier',\n",
    "    'IForestClassifier',\n",
    "    'KNNClassifier',\n",
    "    'LOFClassifier',\n",
    "]\n",
    "# Add classifiers to AutoSklearn pipeline\n",
    "add_to_autosklearn_pipeline(classifiers, search_space)\n",
    "# Create the search space\n",
    "for clf in classifiers:\n",
    "    print('{}: {}'.format(clf, get_search_space_size([clf], search_space)))\n",
    "# Size of the total hyperparameter space\n",
    "total_search_space = get_search_space_size(classifiers, search_space)\n",
    "print('Total space size:', total_search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7288bd6b-151b-47b9-9b68-faeda86b875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Budget estimation parameters\n",
    "times = []\n",
    "per_run_budget = 30\n",
    "n_total = 100 # attempted runs\n",
    "n_succeeded = 0 # succeeded runs\n",
    "n_failed = 0 # failed runs\n",
    "# Loop over total attempts\n",
    "for i in tqdm(range(n_total)):\n",
    "    # Sample a model\n",
    "    idx = random.randint(0, len(classifiers)-1) # index\n",
    "    model = classifiers[idx]\n",
    "    # Create AutoSklearn classifier\n",
    "    cls = AutoSklearnClassifier(\n",
    "        time_left_for_this_task=per_run_budget,\n",
    "        per_run_time_limit=per_run_budget,\n",
    "        include={\n",
    "            'classifier': [model]\n",
    "        },\n",
    "        delete_tmp_folder_after_terminate=False,\n",
    "    )\n",
    "    # Sample a configuration \n",
    "    cs = cls.get_configuration_space(X_train, y_train)\n",
    "    config = cs.sample_configuration()\n",
    "    # Fit the model[configuration]\n",
    "    _, _, run_value = cls.fit_pipeline(\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "        config=config,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "    )\n",
    "    # Check success and store time\n",
    "    if 'SUCCESS' in str(run_value[2]):\n",
    "        times.append(run_value[1])\n",
    "        n_succeeded += 1\n",
    "    else:\n",
    "        n_failed += 1\n",
    "# Report successful vs failed runs\n",
    "print('Runs attempted:\\t\\t\\t', n_total)\n",
    "print('Runs succeeded:\\t\\t\\t', n_succeeded)\n",
    "print('Runs failed:\\t\\t\\t', n_failed)\n",
    "print('Total time passed:\\t\\t', int(np.sum(times)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42ec991-0c1f-4dfc-8eee-e94bcbd80179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "avg_time = round(np.average(times), 2)\n",
    "std_time = round(np.std(times), 2)\n",
    "conf_percentage = 0.01 # percentage of configurations to try\n",
    "n_confs = int(total_search_space * conf_percentage) # configurations needed to run\n",
    "alpha = 0 # 95% confidence\n",
    "n_confs_budget = int(n_confs * (avg_time + alpha * std_time)) \n",
    "# Print statistics\n",
    "print('Average run time per fit:\\t\\t\\t', avg_time)\n",
    "print('Standard deviation of the distribution:\\t\\t', std_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f0bf33-4e2d-4a32-a3a7-4ab5f45e8041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plot\n",
    "from matplotlib import pyplot as plt\n",
    "plt.hist(times, bins=10)\n",
    "plt.xlabel('Execution time in seconds')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('t_hist.png')\n",
    "plt.show()\n",
    "# Shapiro-Wilk test for normality\n",
    "from scipy import stats\n",
    "shapiro_test = stats.shapiro(times)\n",
    "print('Shapiro-Wilk test results:\\n', shapiro_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e89765-0471-4bf5-a716-f0525d81e62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best fit distribution\n",
    "from scipy.stats import gamma\n",
    "from fitter import Fitter\n",
    "# Save results to csv\n",
    "df = pd.DataFrame(times, columns=['Times'])\n",
    "pd.DataFrame.to_csv(df, 'times.csv')\n",
    "df = pd.read_csv('times.csv')\n",
    "f = Fitter(df['Times'].values, distributions=['gamma', 'lognorm', \"beta\", \"burr\", \"norm\"])\n",
    "f.fit()\n",
    "f.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6092ba52-b72b-46c2-a2fe-ac01f905092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentiles\n",
    "p = 0.9 # coverage\n",
    "# Distribution parameters\n",
    "# Change according to best fit distribution\n",
    "a = f.get_best(method = 'sumsquare_error')['gamma']['a']\n",
    "loc = f.get_best(method = 'sumsquare_error')['gamma']['loc']\n",
    "scale = f.get_best(method = 'sumsquare_error')['gamma']['scale']\n",
    "x = gamma.ppf(p, a, loc, scale)\n",
    "print('Percentile {}%: {}'.format(p * 100, x))\n",
    "n_confs = 200 # set if not set prior\n",
    "print('Estimated budget for 1% of configurations:', x * n_confs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
