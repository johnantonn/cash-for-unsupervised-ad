{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c6ee10de-2194-4cc6-beba-1e82972e3fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split\n",
    "p = os.path.abspath('..')\n",
    "sys.path.insert(1, p)\n",
    "from utils import import_dataset, clf_lookup, get_search_space, get_search_space_size\n",
    "# Disable warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4c198379-d0dd-4d31-8344-2a887c281bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of outliers in training set: 0.09992193598750976\n",
      "Ratio of outliers in test set: 0.1\n",
      "Training size: 1281\n",
      "Test size: 550\n"
     ]
    }
   ],
   "source": [
    "# Import dataset\n",
    "df = import_dataset('../../data/Cardiotocography_withoutdupl_norm_10_v10.arff')\n",
    "\n",
    "# Maximum number of samples to keep\n",
    "max_samples = 5000\n",
    "\n",
    "# Subsample if necessary\n",
    "if(len(df) > max_samples):\n",
    "    df = df.sample(n=max_samples)\n",
    "\n",
    "# Extract X, y\n",
    "X  = df.iloc[:, :-1]\n",
    "y = df['outlier']\n",
    "\n",
    "# Split to train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, \n",
    "                                                    random_state=10)\n",
    "\n",
    "print(\"Ratio of outliers in training set:\", len(y_train[y_train==1])/len(y_train))\n",
    "print(\"Ratio of outliers in test set:\", len(y_test[y_test==1])/len(y_test))\n",
    "print(\"Training size:\", len(X_train))\n",
    "print(\"Test size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "37227461-73e4-48bb-a7eb-9466b967ac4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8800.0\n",
      "10.0\n",
      "6800.0\n",
      "2000.0\n",
      "2000.0\n",
      "Total space size: 19610.0\n"
     ]
    }
   ],
   "source": [
    "# PyOD classifiers to include\n",
    "classifiers = [\n",
    "    'CBLOFClassifier',\n",
    "    'COPODClassifier',\n",
    "    'IForestClassifier',\n",
    "    'KNNClassifier',\n",
    "    'LOFClassifier',\n",
    "    # add more\n",
    "]\n",
    "# Create the search space\n",
    "models = []\n",
    "search_spaces = []\n",
    "for clf in classifiers:\n",
    "    models.append(clf_lookup(clf))\n",
    "    print(get_search_space_size([clf]))\n",
    "    search_spaces.append(get_search_space(clf))\n",
    "print('Total space size:', get_search_space_size(classifiers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7288bd6b-151b-47b9-9b68-faeda86b875d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Time\n",
    "times = []\n",
    "# Sample from the model-hyperparam space\n",
    "n_total = 100 # attempted runs\n",
    "n_succeeded = 0 # succeeded runs\n",
    "n_failed = 0 # failed runs\n",
    "for i in tqdm(range(n_total)):\n",
    "    # Step 1 - Sample a model uniformally\n",
    "    idx = random.randint(0, len(models)-1) # index\n",
    "    model = models[idx]\n",
    "    hp_space = search_spaces[idx]\n",
    "\n",
    "    # Step 2 - Sample a configuration from its hyperparam space\n",
    "    params = hp_space.sample_configuration().get_dictionary()\n",
    "    model.set_params(**params)\n",
    "    try:\n",
    "        start = time.time() # start ticking\n",
    "        model.fit(X_train, y_train)\n",
    "        end = time.time() # end ticking\n",
    "        elapsed = end - start # fit time\n",
    "        times.append(elapsed)\n",
    "        n_succeeded += 1\n",
    "    except:\n",
    "        n_failed += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e42ec991-0c1f-4dfc-8eee-e94bcbd80179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runs attempted:\t\t\t 100\n",
      "Runs succeeded:\t\t\t 95\n",
      "Runs failed:\t\t\t 5\n",
      "Total time:\t\t\t 19.061918020248413\n",
      "Average time per run:\t\t 0.20065176863419382\n",
      "Standard deviation:\t\t 0.30313269616966204\n",
      "Estimated 100-run budget:\t 111.00498571431798\n"
     ]
    }
   ],
   "source": [
    "# Report successful vs failed runs\n",
    "print('Runs attempted:\\t\\t\\t', n_total)\n",
    "print('Runs succeeded:\\t\\t\\t', n_succeeded)\n",
    "print('Runs failed:\\t\\t\\t', n_failed)\n",
    "# Cap large execution times\n",
    "cap = 30 # seconds, should be equal to the max allowed threshold for fit()\n",
    "times_cap = []\n",
    "for val in times:\n",
    "    if val > cap:\n",
    "        times_cap.append(cap)\n",
    "    else:\n",
    "        times_cap.append(val)\n",
    "# Print statistics\n",
    "print('Total time:\\t\\t\\t', sum(times_cap))\n",
    "print('Average time per run:\\t\\t', np.average(times_cap))\n",
    "print('Standard deviation:\\t\\t', np.std(times_cap))\n",
    "print('Estimated 100-run budget:\\t', 100 * (np.average(times_cap) + 3 * np.std(times_cap)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
