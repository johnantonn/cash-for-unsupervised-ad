{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1d23e9f-2c4a-48f4-a7c9-4afd22cd2d4d",
   "metadata": {},
   "source": [
    "## Results post-processor\n",
    "This notebook is applied on the experiment results as a post-processing step. It contains the aggregation logic to summarize the results of runs with the same parameters on different dataset splits.\n",
    "\n",
    "The post-processing logic summarizes the results of different splits for the same number of the below parameters:\n",
    "- **Dataset** (ALOI, Annthyroid, Cardiotocography, etc.)\n",
    "- **Search algorithm** (random, edb, smac)\n",
    "- **Validation set strategy** (stratified, balanced)\n",
    "- **Validation set size** (20, 50, 100, 200, etc.)\n",
    "\n",
    "### Example\n",
    "The below raw output files, results of the experiments for different data splits/iterations (assuming the filenaming conventions of the source code):\n",
    "- ALOI_**1**_edb_balanced_100.csv\n",
    "- ALOI_**2**_edb_balanced_100.csv\n",
    "- ALOI_**3**_edb_balanced_100.csv\n",
    "- ALOI_**4**_edb_balanced_100.csv\n",
    "- ALOI_**5**_edb_balanced_100.csv\n",
    "\n",
    "would be summarized in a single file that would contain the average of the above:\n",
    "- **ALOI_edb_balanced_100.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "873e496c-e544-420e-9ac4-ac2b1ac4cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import timedelta as td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86119bfd-43b7-4993-811e-2b850eaeb028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definitions\n",
    "def fill_values(df, total_budget):\n",
    "    '''\n",
    "    Arguments:\n",
    "        df(pd.DataFrame): the dataframe of the results\n",
    "        total_budget(int): the total budget in seconds\n",
    "\n",
    "    Returns:\n",
    "        df(pd.DataFrame): the processed df with `total_budget` rows\n",
    "    '''\n",
    "    # Fill the missing values for `Timestamp` column\n",
    "    ref_idx = 0 # the row index with the current max value\n",
    "    for i in range(1, total_budget):\n",
    "        if i not in df.Timestamp.values:\n",
    "            n = df.shape[0]\n",
    "            df.at[n, 'Timestamp'] = int(i) # keep column name for consistency\n",
    "            df.at[n, 'single_best_optimization_score'] = df.at[ref_idx, 'single_best_optimization_score']\n",
    "            df.at[n, 'single_best_test_score'] = df.at[ref_idx, 'single_best_test_score']\n",
    "        else:\n",
    "            ref_idx = df.index[df['Timestamp'] == i][0]\n",
    "            #print('Changing index at Timestamp =', i)\n",
    "    df = df.iloc[1: , :]\n",
    "    df = df.sort_values(by='Timestamp').reset_index(drop=True)\n",
    "    df = df.astype({\"Timestamp\": int})\n",
    "    return df\n",
    "\n",
    "def get_combinations(search_algorithm_list, validation_strategy_list, validation_size_list):\n",
    "    '''\n",
    "    Function that computes the combinations of the below values:\n",
    "      - search algorithm\n",
    "      - validation strategy\n",
    "      - validation size\n",
    "\n",
    "    Arguments:\n",
    "        search_algorithm_list(list): list of search algorithms\n",
    "        validation_strategy_list(list): list of validation strategy values\n",
    "        validation_size_list(list): list of validation size values\n",
    "\n",
    "    Returns:\n",
    "        cross_prod: the cross product list of combinations as strings\n",
    "    '''\n",
    "    cross_prod = []\n",
    "    for algorithm in search_algorithm_list:\n",
    "        for strategy in validation_strategy_list:\n",
    "            for size in validation_size_list:\n",
    "                cross_prod.append(\n",
    "                    '{}_{}_{}.csv'.format(\n",
    "                        algorithm,\n",
    "                        strategy,\n",
    "                        size\n",
    "                    )\n",
    "                )\n",
    "    return cross_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14c5a039-285f-4277-8dc7-667c1f933d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total budget: 300\n",
      "Dataset list: ['ALOI', 'Annthyroid', 'Cardiotocography', 'SpamBase']\n",
      "Search algorithm list: ['edb', 'random', 'smac']\n",
      "Validation strategy list: ['stratified', 'balanced']\n",
      "Validation size list: [20, 50, 100, 200]\n"
     ]
    }
   ],
   "source": [
    "# Provide the directory of the raw output files\n",
    "# Must contain a folder `raw` and a `metadata.csv` file\n",
    "results_dirname = 'results' # input to the script\n",
    "#\n",
    "# Input/output directories\n",
    "results_path = os.path.join(Path.cwd(), results_dirname)\n",
    "raw_path = os.path.join(results_path, 'raw')\n",
    "output_dir = 'processed'\n",
    "output_path = os.path.join(results_path, output_dir)\n",
    "if os.path.exists(output_path):\n",
    "    raise ValueError(\n",
    "    \"Output directory `{}` already exists.\".format(output_path))\n",
    "else:\n",
    "    os.mkdir(output_path)\n",
    "#\n",
    "# Import metadata\n",
    "metadata_filepath = os.path.join(results_path, 'metadata.csv')\n",
    "metadata_df = pd.read_csv(metadata_filepath)\n",
    "# Remove individual edb runs\n",
    "metadata_df = metadata_df[metadata_df['total_budget'] != 30]\n",
    "#\n",
    "# Extract experiment parameters\n",
    "total_budget = metadata_df.total_budget[0]\n",
    "dataset_list = list(metadata_df.dataset_name.unique())\n",
    "validation_strategy_list = list(metadata_df.validation_strategy.unique())\n",
    "validation_size_list = list(metadata_df.validation_size.unique())\n",
    "search_algorithm_list = list(metadata_df.search_type.unique())\n",
    "#\n",
    "# Print the parameters\n",
    "print('Total budget:', total_budget)\n",
    "print('Dataset list:', dataset_list)\n",
    "print('Search algorithm list:', search_algorithm_list)\n",
    "print('Validation strategy list:', validation_strategy_list)\n",
    "print('Validation size list:', validation_size_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1457e012-86ac-46ea-9082-1db18965dc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ALOI\n",
      "\tSaved aggregate results to: ALOI_edb_stratified_20.csv\n",
      "\tSaved aggregate results to: ALOI_edb_stratified_50.csv\n",
      "\tSaved aggregate results to: ALOI_edb_stratified_100.csv\n",
      "\tSaved aggregate results to: ALOI_edb_stratified_200.csv\n",
      "\tSaved aggregate results to: ALOI_edb_balanced_20.csv\n",
      "\tSaved aggregate results to: ALOI_edb_balanced_50.csv\n",
      "\tSaved aggregate results to: ALOI_edb_balanced_100.csv\n",
      "\tSaved aggregate results to: ALOI_edb_balanced_200.csv\n",
      "\tSaved aggregate results to: ALOI_random_stratified_20.csv\n",
      "\tSaved aggregate results to: ALOI_random_stratified_50.csv\n",
      "\tSaved aggregate results to: ALOI_random_stratified_100.csv\n",
      "\tSaved aggregate results to: ALOI_random_stratified_200.csv\n",
      "\tSaved aggregate results to: ALOI_random_balanced_20.csv\n",
      "\tSaved aggregate results to: ALOI_random_balanced_50.csv\n",
      "\tSaved aggregate results to: ALOI_random_balanced_100.csv\n",
      "\tSaved aggregate results to: ALOI_random_balanced_200.csv\n",
      "\tSaved aggregate results to: ALOI_smac_stratified_20.csv\n",
      "\tSaved aggregate results to: ALOI_smac_stratified_50.csv\n",
      "\tSaved aggregate results to: ALOI_smac_stratified_100.csv\n",
      "\tSaved aggregate results to: ALOI_smac_stratified_200.csv\n",
      "\tSaved aggregate results to: ALOI_smac_balanced_20.csv\n",
      "\tSaved aggregate results to: ALOI_smac_balanced_50.csv\n",
      "\tSaved aggregate results to: ALOI_smac_balanced_100.csv\n",
      "\tSaved aggregate results to: ALOI_smac_balanced_200.csv\n",
      "Processing Annthyroid\n",
      "\tSaved aggregate results to: Annthyroid_edb_stratified_20.csv\n",
      "\tSaved aggregate results to: Annthyroid_edb_stratified_50.csv\n",
      "\tSaved aggregate results to: Annthyroid_edb_stratified_100.csv\n",
      "\tSaved aggregate results to: Annthyroid_edb_stratified_200.csv\n",
      "\tSaved aggregate results to: Annthyroid_edb_balanced_20.csv\n",
      "\tSaved aggregate results to: Annthyroid_edb_balanced_50.csv\n",
      "\tSaved aggregate results to: Annthyroid_edb_balanced_100.csv\n",
      "\tSaved aggregate results to: Annthyroid_edb_balanced_200.csv\n",
      "\tSaved aggregate results to: Annthyroid_random_stratified_20.csv\n",
      "\tSaved aggregate results to: Annthyroid_random_stratified_50.csv\n",
      "\tSaved aggregate results to: Annthyroid_random_stratified_100.csv\n",
      "\tSaved aggregate results to: Annthyroid_random_stratified_200.csv\n",
      "\tSaved aggregate results to: Annthyroid_random_balanced_20.csv\n",
      "\tSaved aggregate results to: Annthyroid_random_balanced_50.csv\n",
      "\tSaved aggregate results to: Annthyroid_random_balanced_100.csv\n",
      "\tSaved aggregate results to: Annthyroid_random_balanced_200.csv\n",
      "\tSaved aggregate results to: Annthyroid_smac_stratified_20.csv\n",
      "\tSaved aggregate results to: Annthyroid_smac_stratified_50.csv\n",
      "\tSaved aggregate results to: Annthyroid_smac_stratified_100.csv\n",
      "\tSaved aggregate results to: Annthyroid_smac_stratified_200.csv\n",
      "\tSaved aggregate results to: Annthyroid_smac_balanced_20.csv\n",
      "\tSaved aggregate results to: Annthyroid_smac_balanced_50.csv\n",
      "\tSaved aggregate results to: Annthyroid_smac_balanced_100.csv\n",
      "\tSaved aggregate results to: Annthyroid_smac_balanced_200.csv\n",
      "Processing Cardiotocography\n",
      "\tSaved aggregate results to: Cardiotocography_edb_stratified_20.csv\n",
      "\tSaved aggregate results to: Cardiotocography_edb_stratified_50.csv\n",
      "\tSaved aggregate results to: Cardiotocography_edb_stratified_100.csv\n",
      "\tSaved aggregate results to: Cardiotocography_edb_stratified_200.csv\n",
      "\tSaved aggregate results to: Cardiotocography_edb_balanced_20.csv\n",
      "\tSaved aggregate results to: Cardiotocography_edb_balanced_50.csv\n",
      "\tSaved aggregate results to: Cardiotocography_edb_balanced_100.csv\n",
      "\tSaved aggregate results to: Cardiotocography_edb_balanced_200.csv\n",
      "\tSaved aggregate results to: Cardiotocography_random_stratified_20.csv\n",
      "\tSaved aggregate results to: Cardiotocography_random_stratified_50.csv\n",
      "\tSaved aggregate results to: Cardiotocography_random_stratified_100.csv\n",
      "\tSaved aggregate results to: Cardiotocography_random_stratified_200.csv\n",
      "\tSaved aggregate results to: Cardiotocography_random_balanced_20.csv\n",
      "\tSaved aggregate results to: Cardiotocography_random_balanced_50.csv\n",
      "\tSaved aggregate results to: Cardiotocography_random_balanced_100.csv\n",
      "\tSaved aggregate results to: Cardiotocography_random_balanced_200.csv\n",
      "\tSaved aggregate results to: Cardiotocography_smac_stratified_20.csv\n",
      "\tSaved aggregate results to: Cardiotocography_smac_stratified_50.csv\n",
      "\tSaved aggregate results to: Cardiotocography_smac_stratified_100.csv\n",
      "\tSaved aggregate results to: Cardiotocography_smac_stratified_200.csv\n",
      "\tSaved aggregate results to: Cardiotocography_smac_balanced_20.csv\n",
      "\tSaved aggregate results to: Cardiotocography_smac_balanced_50.csv\n",
      "\tSaved aggregate results to: Cardiotocography_smac_balanced_100.csv\n",
      "\tSaved aggregate results to: Cardiotocography_smac_balanced_200.csv\n",
      "Processing SpamBase\n",
      "\tSaved aggregate results to: SpamBase_edb_stratified_20.csv\n",
      "\tSaved aggregate results to: SpamBase_edb_stratified_50.csv\n",
      "\tSaved aggregate results to: SpamBase_edb_stratified_100.csv\n",
      "\tSaved aggregate results to: SpamBase_edb_stratified_200.csv\n",
      "\tSaved aggregate results to: SpamBase_edb_balanced_20.csv\n",
      "\tSaved aggregate results to: SpamBase_edb_balanced_50.csv\n",
      "\tSaved aggregate results to: SpamBase_edb_balanced_100.csv\n",
      "\tSaved aggregate results to: SpamBase_edb_balanced_200.csv\n",
      "\tSaved aggregate results to: SpamBase_random_stratified_20.csv\n",
      "\tSaved aggregate results to: SpamBase_random_stratified_50.csv\n",
      "\tSaved aggregate results to: SpamBase_random_stratified_100.csv\n",
      "\tSaved aggregate results to: SpamBase_random_stratified_200.csv\n",
      "\tSaved aggregate results to: SpamBase_random_balanced_20.csv\n",
      "\tSaved aggregate results to: SpamBase_random_balanced_50.csv\n",
      "\tSaved aggregate results to: SpamBase_random_balanced_100.csv\n",
      "\tSaved aggregate results to: SpamBase_random_balanced_200.csv\n",
      "\tSaved aggregate results to: SpamBase_smac_stratified_20.csv\n",
      "\tSaved aggregate results to: SpamBase_smac_stratified_50.csv\n",
      "\tSaved aggregate results to: SpamBase_smac_stratified_100.csv\n",
      "\tSaved aggregate results to: SpamBase_smac_stratified_200.csv\n",
      "\tSaved aggregate results to: SpamBase_smac_balanced_20.csv\n",
      "\tSaved aggregate results to: SpamBase_smac_balanced_50.csv\n",
      "\tSaved aggregate results to: SpamBase_smac_balanced_100.csv\n",
      "\tSaved aggregate results to: SpamBase_smac_balanced_200.csv\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Calculate combinations\n",
    "cross_prod = get_combinations(search_algorithm_list, validation_strategy_list, validation_size_list)\n",
    "# Aggregate results\n",
    "for dataset in dataset_list:\n",
    "    print('Processing', dataset)\n",
    "    for cp in cross_prod:\n",
    "        df_list = [] # list to store processed results\n",
    "        # Process raw results\n",
    "        for filename in os.listdir(raw_path):\n",
    "            if dataset in filename and cp in filename:\n",
    "                df = pd.read_csv(\n",
    "                    os.path.join(\n",
    "                        raw_path,\n",
    "                        filename\n",
    "                    ),\n",
    "                    parse_dates=['Timestamp']\n",
    "                )\n",
    "                df.drop(columns=['single_best_train_score'], inplace=True)\n",
    "                # Transform timestamp and boundary values\n",
    "                df.Timestamp = (df.Timestamp-df.Timestamp[0]).apply(td.total_seconds)\n",
    "                n = df.shape[0]\n",
    "                df.at[n, 'Timestamp'] = total_budget\n",
    "                df = df.astype({\"Timestamp\": int})\n",
    "                df.at[n, 'single_best_optimization_score'] = df.at[n-1, 'single_best_optimization_score']\n",
    "                df.at[n, 'single_best_test_score'] = df.at[n-1, 'single_best_test_score']\n",
    "                df = df.drop_duplicates().reset_index(drop=True)\n",
    "                df = fill_values(df, total_budget)\n",
    "                df_list.append(df)\n",
    "        # Average individual results\n",
    "        if len(df_list) > 0:\n",
    "            df_agg = df_list[0] # aggregate results\n",
    "            for df in df_list[1:]:\n",
    "                df_agg['single_best_optimization_score'] += df['single_best_optimization_score']\n",
    "                df_agg['single_best_test_score'] += df['single_best_test_score']\n",
    "            df_agg['single_best_optimization_score'] = df_agg['single_best_optimization_score'] / len(df_list)\n",
    "            df_agg['single_best_test_score'] = df_agg['single_best_test_score'] / len(df_list)\n",
    "            df_agg = df_agg.astype({\"Timestamp\": int})\n",
    "            # Save aggregate results to csv\n",
    "            out_filename = dataset+'_'+cp\n",
    "            df_agg.to_csv(os.path.join(output_path, out_filename), index=False)\n",
    "            print('\\tSaved aggregate results to:', out_filename)\n",
    "print('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
