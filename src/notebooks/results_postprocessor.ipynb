{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1d23e9f-2c4a-48f4-a7c9-4afd22cd2d4d",
   "metadata": {},
   "source": [
    "# Results post-processor\n",
    "This notebook is applied on the experiment results as a post-processing step. It contains the aggregation logic to summarize the results of runs with the same parameters on different dataset splits.\n",
    "\n",
    "The post-processing logic summarizes the results of different splits for the same number of the below parameters:\n",
    "- **Dataset** (ALOI, Annthyroid, Cardiotocography, etc.)\n",
    "- **Search algorithm** (random, ue, smac)\n",
    "- **Validation set strategy** (stratified, balanced)\n",
    "- **Validation set size** (20, 50, 100, 200, etc.)\n",
    "\n",
    "## Example\n",
    "The below raw output files, results of the experiments for different data splits/iterations (assuming the filenaming conventions of the source code):\n",
    "- ALOI_**1**_ue_balanced_100.csv\n",
    "- ALOI_**2**_ue_balanced_100.csv\n",
    "- ALOI_**3**_ue_balanced_100.csv\n",
    "- ALOI_**4**_ue_balanced_100.csv\n",
    "- ALOI_**5**_ue_balanced_100.csv\n",
    "\n",
    "would be summarized in a single file that would contain the average of the above:\n",
    "- **ALOI_ue_balanced_100.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "873e496c-e544-420e-9ac4-ac2b1ac4cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from notebook_utils import preprocess_df, fill_values, get_combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93161d17-cbfb-4a16-ba70-bf076b4c466b",
   "metadata": {},
   "source": [
    "## Setup and metadata\n",
    "This cell defines the necessary variables by parsing the `metadata.csv` file provided in the results directory. It also creates the output directory where the processed files will later be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c5a039-285f-4277-8dc7-667c1f933d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total budget: 300\n",
      "Dataset list: ['ALOI', 'Annthyroid', 'Cardiotocography']\n",
      "Search algorithm list: ['edb', 'random', 'smac']\n",
      "Validation strategy list: ['stratified', 'balanced']\n",
      "Validation size list: [20, 50, 100, 200]\n"
     ]
    }
   ],
   "source": [
    "# Provide the directory of the raw output files\n",
    "# Must contain a folder `raw` and a `metadata.csv` file\n",
    "results_dirname = '../results/results' # input to the script\n",
    "#\n",
    "# Input/output directories\n",
    "results_path = os.path.join(Path.cwd(), results_dirname)\n",
    "raw_path = os.path.join(results_path, 'raw')\n",
    "output_dir = 'processed'\n",
    "output_path = os.path.join(results_path, output_dir)\n",
    "if os.path.exists(output_path):\n",
    "    raise ValueError(\n",
    "    \"Output directory `{}` already exists.\".format(output_path))\n",
    "else:\n",
    "    os.mkdir(output_path)\n",
    "#\n",
    "# Import metadata\n",
    "metadata_filepath = os.path.join(results_path, 'metadata.csv')\n",
    "metadata_df = pd.read_csv(metadata_filepath)\n",
    "# Remove individual ue runs\n",
    "metadata_df = metadata_df[metadata_df['total_budget'] != 30]\n",
    "#\n",
    "# Extract experiment parameters\n",
    "total_budget = metadata_df.total_budget[0]\n",
    "dataset_list = list(metadata_df.dataset_name.unique())\n",
    "validation_strategy_list = list(metadata_df.validation_strategy.unique())\n",
    "validation_size_list = list(metadata_df.validation_size.unique())\n",
    "search_algorithm_list = list(metadata_df.search_type.unique())\n",
    "#\n",
    "# Print the parameters\n",
    "print('Total budget:', total_budget)\n",
    "print('Dataset list:', dataset_list)\n",
    "print('Search algorithm list:', search_algorithm_list)\n",
    "print('Validation strategy list:', validation_strategy_list)\n",
    "print('Validation size list:', validation_size_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3ef0da-1232-4ff6-8523-c40e2d542a12",
   "metadata": {},
   "source": [
    "## Core processing\n",
    "This cell contains the core processing logic of this notebook. It iterates over all datasets and searches for the appropriate combinations of search algorithm, validation set strategy and size, and transforms the performance results to the appropriate format, before saving them to the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1457e012-86ac-46ea-9082-1db18965dc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ALOI\n",
      "\tSaved aggregate results to: ALOI_edb_stratified_20.csv\n",
      "\tSaved aggregate results to: ALOI_edb_stratified_50.csv\n",
      "\tSaved aggregate results to: ALOI_edb_stratified_100.csv\n",
      "\tSaved aggregate results to: ALOI_edb_stratified_200.csv\n",
      "\tSaved aggregate results to: ALOI_edb_balanced_20.csv\n",
      "\tSaved aggregate results to: ALOI_edb_balanced_50.csv\n",
      "\tSaved aggregate results to: ALOI_edb_balanced_100.csv\n",
      "\tSaved aggregate results to: ALOI_edb_balanced_200.csv\n",
      "\tSaved aggregate results to: ALOI_random_stratified_20.csv\n",
      "\tSaved aggregate results to: ALOI_random_stratified_50.csv\n",
      "\tSaved aggregate results to: ALOI_random_stratified_100.csv\n",
      "\tSaved aggregate results to: ALOI_random_stratified_200.csv\n",
      "\tSaved aggregate results to: ALOI_random_balanced_20.csv\n",
      "\tSaved aggregate results to: ALOI_random_balanced_50.csv\n",
      "\tSaved aggregate results to: ALOI_random_balanced_100.csv\n",
      "\tSaved aggregate results to: ALOI_random_balanced_200.csv\n",
      "\tSaved aggregate results to: ALOI_smac_stratified_20.csv\n",
      "\tSaved aggregate results to: ALOI_smac_stratified_50.csv\n",
      "\tSaved aggregate results to: ALOI_smac_stratified_100.csv\n",
      "\tSaved aggregate results to: ALOI_smac_stratified_200.csv\n",
      "\tSaved aggregate results to: ALOI_smac_balanced_20.csv\n",
      "\tSaved aggregate results to: ALOI_smac_balanced_50.csv\n",
      "\tSaved aggregate results to: ALOI_smac_balanced_100.csv\n",
      "\tSaved aggregate results to: ALOI_smac_balanced_200.csv\n",
      "Processing Annthyroid\n",
      "\tSaved aggregate results to: Annthyroid_edb_stratified_20.csv\n",
      "\tSaved aggregate results to: Annthyroid_edb_stratified_50.csv\n",
      "\tSaved aggregate results to: Annthyroid_edb_stratified_100.csv\n",
      "\tSaved aggregate results to: Annthyroid_edb_stratified_200.csv\n",
      "\tSaved aggregate results to: Annthyroid_edb_balanced_20.csv\n",
      "\tSaved aggregate results to: Annthyroid_edb_balanced_50.csv\n",
      "\tSaved aggregate results to: Annthyroid_edb_balanced_100.csv\n",
      "\tSaved aggregate results to: Annthyroid_edb_balanced_200.csv\n",
      "\tSaved aggregate results to: Annthyroid_random_stratified_20.csv\n",
      "\tSaved aggregate results to: Annthyroid_random_stratified_50.csv\n",
      "\tSaved aggregate results to: Annthyroid_random_stratified_100.csv\n",
      "\tSaved aggregate results to: Annthyroid_random_stratified_200.csv\n",
      "\tSaved aggregate results to: Annthyroid_random_balanced_20.csv\n",
      "\tSaved aggregate results to: Annthyroid_random_balanced_50.csv\n",
      "\tSaved aggregate results to: Annthyroid_random_balanced_100.csv\n",
      "\tSaved aggregate results to: Annthyroid_random_balanced_200.csv\n",
      "\tSaved aggregate results to: Annthyroid_smac_stratified_20.csv\n",
      "\tSaved aggregate results to: Annthyroid_smac_stratified_50.csv\n",
      "\tSaved aggregate results to: Annthyroid_smac_stratified_100.csv\n",
      "\tSaved aggregate results to: Annthyroid_smac_stratified_200.csv\n",
      "\tSaved aggregate results to: Annthyroid_smac_balanced_20.csv\n",
      "\tSaved aggregate results to: Annthyroid_smac_balanced_50.csv\n",
      "\tSaved aggregate results to: Annthyroid_smac_balanced_100.csv\n",
      "\tSaved aggregate results to: Annthyroid_smac_balanced_200.csv\n",
      "Processing Cardiotocography\n",
      "\tSaved aggregate results to: Cardiotocography_edb_stratified_20.csv\n",
      "\tSaved aggregate results to: Cardiotocography_edb_stratified_50.csv\n",
      "\tSaved aggregate results to: Cardiotocography_edb_stratified_100.csv\n",
      "\tSaved aggregate results to: Cardiotocography_edb_stratified_200.csv\n",
      "\tSaved aggregate results to: Cardiotocography_edb_balanced_20.csv\n",
      "\tSaved aggregate results to: Cardiotocography_edb_balanced_50.csv\n",
      "\tSaved aggregate results to: Cardiotocography_edb_balanced_100.csv\n",
      "\tSaved aggregate results to: Cardiotocography_edb_balanced_200.csv\n",
      "\tSaved aggregate results to: Cardiotocography_random_stratified_20.csv\n",
      "\tSaved aggregate results to: Cardiotocography_random_stratified_50.csv\n",
      "\tSaved aggregate results to: Cardiotocography_random_stratified_100.csv\n",
      "\tSaved aggregate results to: Cardiotocography_random_stratified_200.csv\n",
      "\tSaved aggregate results to: Cardiotocography_random_balanced_20.csv\n",
      "\tSaved aggregate results to: Cardiotocography_random_balanced_50.csv\n",
      "\tSaved aggregate results to: Cardiotocography_random_balanced_100.csv\n",
      "\tSaved aggregate results to: Cardiotocography_random_balanced_200.csv\n",
      "\tSaved aggregate results to: Cardiotocography_smac_stratified_20.csv\n",
      "\tSaved aggregate results to: Cardiotocography_smac_stratified_50.csv\n",
      "\tSaved aggregate results to: Cardiotocography_smac_stratified_100.csv\n",
      "\tSaved aggregate results to: Cardiotocography_smac_stratified_200.csv\n",
      "\tSaved aggregate results to: Cardiotocography_smac_balanced_20.csv\n",
      "\tSaved aggregate results to: Cardiotocography_smac_balanced_50.csv\n",
      "\tSaved aggregate results to: Cardiotocography_smac_balanced_100.csv\n",
      "\tSaved aggregate results to: Cardiotocography_smac_balanced_200.csv\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Calculate combinations\n",
    "cross_prod = get_combinations(search_algorithm_list, validation_strategy_list, validation_size_list)\n",
    "# Aggregate results\n",
    "for dataset in dataset_list:\n",
    "    print('Processing', dataset)\n",
    "    for cp in cross_prod:\n",
    "        df_list = [] # list to store processed results\n",
    "        # Process raw results\n",
    "        for filename in os.listdir(raw_path):\n",
    "            if dataset in filename and cp in filename:\n",
    "                df = pd.read_csv(os.path.join(raw_path, filename),\n",
    "                    usecols = [\n",
    "                        'Timestamp',\n",
    "                        'single_best_optimization_score',\n",
    "                        'single_best_test_score'\n",
    "                    ],\n",
    "                    parse_dates=['Timestamp']\n",
    "                )\n",
    "                # Transform timestamp and boundary values\n",
    "                df = preprocess_df(df, total_budget)\n",
    "                # Fill missing values from 1 to total_budget seconds\n",
    "                df = fill_values(df, total_budget)\n",
    "                # Append to list of dataframes\n",
    "                df_list.append(df)\n",
    "        # Extract stats\n",
    "        if len(df_list) > 0:\n",
    "            # Average individual results\n",
    "            df_agg = df_list[0] # aggregate results\n",
    "            for df in df_list[1:]:\n",
    "                df_agg['single_best_optimization_score'] += df['single_best_optimization_score']\n",
    "                df_agg['single_best_test_score'] += df['single_best_test_score']\n",
    "            df_agg['single_best_optimization_score'] = df_agg['single_best_optimization_score'] / len(df_list)\n",
    "            df_agg['single_best_test_score'] = df_agg['single_best_test_score'] / len(df_list)\n",
    "            df_agg = df_agg.astype({\"Timestamp\": int})\n",
    "            # Compute std\n",
    "            df_opt = pd.concat([df['single_best_optimization_score'] for df in df_list], axis=1)\n",
    "            df_test = pd.concat([df['single_best_test_score'] for df in df_list], axis=1)\n",
    "            y_std_opt = df_opt.std(axis=1).to_numpy()\n",
    "            y_std_test = df_test.std(axis=1).to_numpy()\n",
    "            df_agg['single_best_optimization_score_std'] = y_std_opt\n",
    "            df_agg['single_best_test_score_std'] = y_std_test\n",
    "            # Save aggregate results to csv\n",
    "            out_filename = dataset+'_'+cp\n",
    "            df_agg.to_csv(os.path.join(output_path, out_filename), index=False)\n",
    "            print('\\tSaved aggregate results to:', out_filename)\n",
    "print('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
