{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc934a5a-d005-40d5-87d3-9be003f9639d",
   "metadata": {},
   "source": [
    "## Process original datasets to generate static train/test files\n",
    "The original datasets used are obtained from [here](https://www.dbs.ifi.lmu.de/research/outlier-evaluation/DAMI/) and undergo a preprocessing phase to generate static train/test files that are stored on disk to be used later in the experiments.\n",
    "\n",
    "### Datasets\n",
    "Download original versions of each dataset (unnormalized, without duplicates):\n",
    "\n",
    "| Name | Description | Total Instances | Outliers | Attributes |\n",
    "|:--- |:--- | --- | --- | --- |\n",
    "| ALOI | This dataset is a collection of images used for outlier detection in different representations. | 50000 | 1508 | 27 |\n",
    "| Annthyroid | This data set contains medical data on hypothyroidism. | 7200 | 534 | 21 |\n",
    "| Arrhythmia | Patient records classified as normal or as exhibiting some type of cardiac arrhythmia. | 450 | 206 | 259 |\n",
    "| Cardiotococraphy | Data set related to heart diseases. | 2126 | 471 | 21 |\n",
    "| KDDCup99 | This dataset captures different types of network intrusions or attacks. | 60632 | 246 | 38+3 |\n",
    "| SpamBase | A data set representing emails classified as spam (outliers) or nonspam. | 4601 | 1813 | 57 |\n",
    "| Waveform | This dataset represents 3 classes of waves.  | 3443 | 100 | 21 |\n",
    "\n",
    "### Steps\n",
    "For each dataset:\n",
    "  - Load dataset and subsample according to `max_samples`\n",
    "  - Split to train/test sets iteratively according to `num_iters` using `shuffling`\n",
    "  - Standardize the training set and apply to test set\n",
    "  - Save train/test sets to disk as csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024ac160-0e72-4b2a-9c48-0160b607b6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from notebook_utils import import_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdea4f4-4a3f-4556-bf3e-2f7a24c90a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions that prints normal/outlier numbers given a list of 0/1 labels\n",
    "def print_dist(y):\n",
    "    n_outliers = np.sum(y) # assuming 0/1 labels\n",
    "    n_normal = len(y) - n_outliers\n",
    "    assert(n_outliers + n_normal == len(y))\n",
    "    print('\\tTotal:', len(y))\n",
    "    print('\\tNormal:', n_normal)\n",
    "    print('\\tOutliers:', n_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067f712f-66c5-40e1-aa4e-54aea2b7a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing parameters\n",
    "data_dir = '../data' # root directory of the data\n",
    "max_samples = 5000 # max number of points per dataset\n",
    "num_iters = 10 # number of train/test sets to create\n",
    "# Filenames of the original datasets\n",
    "dataset_list = [\n",
    "    'ALOI_withoutdupl.arff',\n",
    "    'Annthyroid_withoutdupl_07.arff',\n",
    "    'Arrhythmia_withoutdupl_46.arff',\n",
    "    'Cardiotocography_withoutdupl_22.arff',\n",
    "    'KDDCup99_withoutdupl_catremoved.arff',\n",
    "    'SpamBase_withoutdupl_40.arff',\n",
    "    'Waveform_withoutdupl_v10.arff'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daab3922-c545-42e0-b21f-b05d85d21426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over dataset list\n",
    "for dataset in dataset_list:\n",
    "    d_name = dataset.split('_')[0]\n",
    "    print('Processing', d_name)\n",
    "    d_dir = data_dir + '/original/' + dataset\n",
    "    df = import_dataset(d_dir)\n",
    "    # Subsample if too large\n",
    "    if d_name == 'KDDCup99':\n",
    "        df_1 = df[df['outlier']==1] # outliers\n",
    "        df_0 = df[df['outlier']==0] # normals\n",
    "        n_samples = max_samples - df_1.shape[0]\n",
    "        df_0_sample = df_0.sample(n=n_samples)\n",
    "        df = pd.concat([df_0_sample, df_1])\n",
    "    elif(df.shape[0] > max_samples):\n",
    "        df = df.sample(n=max_samples)\n",
    "    # Extract X, y\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df['outlier']\n",
    "    # Loop over iters\n",
    "    for i in range(1, num_iters+1):\n",
    "        # Split to train/test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.25, stratify=y, shuffle=True, random_state=i)\n",
    "        # Standardize\n",
    "        scaler = StandardScaler()\n",
    "        X_train_norm = scaler.fit_transform(X_train)\n",
    "        X_test_norm = scaler.transform(X_test)\n",
    "        # Convert to DataFrames\n",
    "        X_train_norm_df = pd.DataFrame(X_train_norm, columns=X_train.columns)\n",
    "        X_test_norm_df = pd.DataFrame(X_test_norm, columns=X_test.columns)\n",
    "        # Save to disk\n",
    "        parent_dir = '{}/processed/{}/iter{}'.format(data_dir, d_name, str(i))\n",
    "        # Create parent dir if not exists\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "        X_train_norm_df.to_csv(parent_dir + '/X_train.csv', index = False)\n",
    "        y_train.to_csv(parent_dir + '/y_train.csv', index = False)\n",
    "        X_test_norm_df.to_csv(parent_dir + '/X_test.csv', index = False)\n",
    "        y_test.to_csv(parent_dir + '/y_test.csv', index = False)\n",
    "    # print distributions of last iter\n",
    "    print('Training set:')\n",
    "    print_dist(y_train)\n",
    "    print('Files saved to disk\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
